{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = sagemaker.Session()\n",
    "bucket = 'buck9'\n",
    "path = 'data'\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "contents = s3.list_objects(Bucket=bucket, Prefix=path)['Contents']\n",
    "for content in contents:\n",
    "    print(content['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ''\n",
    "files = ['file1','file2','file3','file4','file5']\n",
    "for file in files:\n",
    "    text = s3.get_object(Bucket = bucket,Key = 'data/'+str(file)+'.txt')\n",
    "    text['Body']\n",
    "    with io.FileIO('sample.txt', 'w') as file2:\n",
    "        for i in text['Body']:\n",
    "            file2.write(i)\n",
    "    f = open(\"sample.txt\", \"r\")\n",
    "    data = data + f.read()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(io.StringIO(data), sep =\".\",header = None).T\n",
    "df.columns = ['sentence']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(0,30):\n",
    "  sentence = re.sub('[^a-zA-Z]',' ',str(df['sentence'][i]))\n",
    "  sentence = sentence.lower() \n",
    "  sentence = sentence.split()\n",
    "  ps = PorterStemmer()\n",
    "  all_stopwords = stopwords.words('english')\n",
    "  sentence = [ps.stem(word) for word in sentence if not word in set(all_stopwords)]\n",
    "  sentence = ' '.join(sentence)\n",
    "  corpus.append(sentence)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (\" \".join(corpus))\n",
    "f = open(\"results.txt\", \"a\")\n",
    "f.write(result)\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join('results','results.txt')).upload_file('results.txt')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "encoded_words = le.fit_transform(result.split(\" \"))\n",
    "encoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "wcss = []\n",
    "for i in range(1, 5):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
    "    kmeans.fit(encoded_words.reshape(-1,1))\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 5), wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 2, init = 'k-means++', random_state = 42)\n",
    "y_kmeans = kmeans.fit_predict(encoded_words.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(encoded_words)):\n",
    "    print(encoded_words[i],\" ==> K = \",y_kmeans[i])"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
